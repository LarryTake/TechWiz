---
layout: default
---

# Speakers

We are happy to feature the following awesome speakers&nbsp;(this list
is expanded on a rolling basis, stay tuned for more!):

## Javier Arsuaga

| <img src="/assets/images/speakers/ja.jpg" alt="Javier Arsuaga" height="250px" /> |

## Fernando Gama

| <img src="/assets/images/speakers/fg.jpg" alt="Fernando Gama" height="250px" /> |

## Théo Lacombe 

| <img src="/assets/images/speakers/tl.jpg" alt="Théo Lacombe" height="250px" /> |
| **Foundations Talk on Topological Data Analysis** |
| This talk provides a short introduction to topological data analysis (TDA), a recent field in data sciences whose goal is to extract topological information from complex objects (graphs, time series, manifold). The presentation focuses on persistence diagrams (PDs), a very common topological descriptor, targeting statistical and learning applications. We present the standard metrics used to compare PDs and discuss their relation with Optimal Transport problems, an important connection when it comes to develop new theoretical and numerical tools in TDA. |

## Yan Leng

| <img src="/assets/images/speakers/yl.jpg" alt="Yan Leng" height="250px" /> |
| **Interpretable Recommender System With Heterogeneous Information: A Geometric Deep Learning Perspective** |
| Recommender systems (RS) are ubiquitous in digital space. This paper develops a deep learning-based approach to address three practical challenges in RS: complex structures of high-dimensional data, noise in relational information, and the black-box nature of machine learning algorithms. Our method—Multi-GraphGraph Attention Network (MG-GAT)—learns latent user and business representations by aggregating a diverse set of information from neighbors of each user (business) on a neighbor importance graph. MG-GAT out-performs state-of-the-art deep learning models in the recommendation task using two large-scale datasets collected from Yelp and four other standard datasets in RS. The improved performance highlights MG-GAT’s advantage in incorporating multi-modal features in a principled manner. The features importance, neighbor importance graph, and latent representations reveal business insights on predictive features and explainable characteristics of business and users. Moreover, the learned neighbor importance graph can be used in a variety of management applications, such as targeting customers, promoting new businesses, and designing information acquisition strategies. Our paper presents a quintessential big data application of deep learning models in management while providing interpretability essential for real-world decision-making. |

## Gal Mishne

| <img src="/assets/images/speakers/gm.jpg" alt="Gal Mishne" height="250px" /> |

## Marinka Zitnik

| <img src="/assets/images/speakers/mz.jpg" alt="Marinka Zitnik" height="250px" /> |
| **Few-Shot Learning for Network Biology** |
| Prevailing methods for graphs require abundant label and edge information for learning. However, labeled examples can be incredibly scarce for problems at the frontier of science. In this talk, I describe our efforts to expand the scope and ease the applicability of graph representation learning. First, I will outline G-Meta, a meta-learning algorithm for graphs. G-Meta quickly adapts to a new task using only a handful of nodes or edges in the new task and does so by learning from local subgraphs in other graphs or related, albeit disjoint, label sets.  G-Meta is theoretically justified as we show that the evidence for a prediction can be found in the local subgraph surrounding the target node or edge. Next, I will discuss applications. The new methods successfully predicted treatments for an emerging disease, which were later experimentally confirmed in the wet laboratory. Unlike previous methods, G-Meta successfully learns in few-shot settings that require generalization to completely new graphs and labels. Finally, G-Meta scales to large graphs, which we demonstrate on a dataset comprising 1,840 graphs spanning the tree of life, a two-orders of magnitude increase in the number of graphs used in prior work. |
